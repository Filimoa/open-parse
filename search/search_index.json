{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Open Parse","text":"<p>Easily chunk complex documents the same way a human would. </p> <p>Chunking documents is a challenging task that underpins any RAG system.  High quality results are critical to a sucessful AI application, yet most open-source libraries are limited in their ability to handle complex documents.  </p> <p>Open Parse is designed to fill this gap by providing a flexible, easy-to-use library capable of visually discerning document layouts and chunking them effectively.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\udd0d Visually-Driven: Open-Parse visually analyzes documents for superior LLM input, going beyond naive text splitting.</li> <li>\u270d\ufe0f Markdown Support: Basic markdown support for parsing headings, bold and italics.</li> <li>\ud83d\udcca High-Precision Table Support: Extract tables into clean Markdown formats with accuracy that surpasses traditional tools.</li> <li>\ud83d\udee0\ufe0f Extensible: Easily implement your own post-processing steps.</li> <li>\ud83d\udca1Intuitive: Great editor support. Completion everywhere. Less time debugging.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#basic-example","title":"Basic Example","text":"<pre><code>import openparse\n\nbasic_doc_path = \"./sample-docs/mobile-home-manual.pdf\"\nparser = openparse.DocumentParser()\nparsed_basic_doc = parser.parse(basic_doc_path)\n\nfor node in parsed_basic_doc.nodes:\n    print(node)\n</code></pre> <p>\ud83d\udcd3 Try the sample notebook here</p>"},{"location":"#semantic-processing-example","title":"Semantic Processing Example","text":"<p>Chunking documents is fundamentally about grouping similar semantic nodes together. By embedding the text of each node, we can then cluster them together based on their similarity.</p> <pre><code>from openparse import processing, DocumentParser\n\nsemantic_pipeline = processing.SemanticIngestionPipeline(\n    openai_api_key=OPEN_AI_KEY,\n    model=\"text-embedding-3-large\",\n    min_tokens=64,\n    max_tokens=1024,\n)\nparser = DocumentParser(\n    processing_pipeline=semantic_pipeline,\n)\nparsed_content = parser.parse(basic_doc_path)\n</code></pre> <p>\ud83d\udcd3 Sample notebook here</p> <p></p>"},{"location":"#cookbooks","title":"Cookbooks","text":"<p>Other Cookbooks</p>"},{"location":"#sponsors","title":"Sponsors","text":"<p>Does your use case need something special? Reach out.</p>"},{"location":"config/","title":"Config","text":"<p>If you're using the ml dependencies, the config class manages the computational device settings for your project,</p>"},{"location":"config/#config","title":"Config","text":"<p>This is a simple wrapper around pytorch. Setting the device will fail if pytorch is not installed.</p> <pre><code>import openparse\n\nopenparse.config.set_device(\"cpu\")\n</code></pre> <p>Note if you're on apple silicon, setting this to <code>mps</code> runs significantly slower than on <code>cpu</code>.</p>"},{"location":"integrations/","title":"Integrations","text":""},{"location":"integrations/#llama-index","title":"Llama Index","text":"<p>We have a simple integration with Llama Index. You can convert the parsed document to Llama Index nodes and then create an index from those nodes.</p> <pre><code>import openparse\nfrom llama_index.core import VectorStoreIndex\n\ndoc_path = \"./sample-docs/lyft-10k.pdf\"\nparser = openparse.DocumentParser()\nparsed_doc = parser.parse(doc_path)\n\nnodes = parsed_doc.to_llama_index_nodes()\nindex = VectorStoreIndex(nodes=nodes)\n</code></pre> <p>Now you can query the index </p> <pre><code>query_engine = index.as_query_engine()\nresponse = query_engine.query(\"What do they do to make money?\")\nprint(response)\n</code></pre> <p>You can also add nodes to an existing index</p> <pre><code>existing_index.insert_nodes(nodes)\n</code></pre>"},{"location":"serialization/","title":"Serializing Results","text":"<p>Beyond accessing model attributes directly via their field names (e.g. parsed_content.text), models can be converted, dumped, serialized, and exported in a number of ways.</p>"},{"location":"serialization/#converting-models-to-dictionaries","title":"Converting Models to Dictionaries","text":"<p>This is the primary way of converting a model to a dictionary.</p> <pre><code>parsed_content.dict()\n</code></pre>"},{"location":"serialization/#converting-models-to-json","title":"Converting Models to JSON","text":"<p>You can run the following to convert the results to a python dict that can be serialized to JSON. <pre><code>parsed_content.json()\n</code></pre></p> <p>Optionally you can also run <code>.model_dump_json()</code> which serializes the results directly to a JSON-encoded string.</p> <pre><code>parsed_content.model_dump_json()\n</code></pre>"},{"location":"visualization/","title":"Visualization","text":""},{"location":"visualization/#displaying-results-within-a-jupyter-notebook","title":"Displaying Results within a Jupyter Notebook","text":"<p>The <code>Node</code> class has built in support for rendering it's text contents as markdown in a <code>jupyter</code> notebook.</p> <p><pre><code>import openparse\n\nbasic_doc_path = \"./sample-docs/mobile-home-manual.pdf\"\nparser = openparse.DocumentParser()\nparsed_basic_doc = parser.parse(basic_doc_path)\n\nfor node in parsed_basic_doc.nodes:\n    display(node)\n</code></pre> </p> <p> </p> <p>You can also display the results directly overlayed on the original pdf.</p> <pre><code>pdf = openparse.Pdf(basic_doc_path)\npdf.display_with_bboxes(\n    parsed_basic_doc.nodes,\n)\n</code></pre> <p></p> <p> </p>"},{"location":"visualization/#exporting-overlayed-results-to-a-pdf","title":"Exporting Overlayed Results to a Pdf","text":"<p>You can also export the results marked up over the original pdf to a seperate pdf file.</p> <pre><code>pdf = openparse.Pdf(basic_doc_path)\npdf.export_with_bboxes(\n    parsed_basic_doc.nodes,\n    output_pdf=\"./sample-docs/mobile-home-manual-marked-up.pdf\"\n)\n</code></pre>"},{"location":"processing/customization/","title":"Customization","text":"<p>While we've chosen sensible defaults, you can add custom processing functions to the <code>DocumentParser</code> class to further process the extracted data.</p> <pre><code>from openparse import processing, Node\nfrom typing import List\n\n\nclass CustomCombineTables(processing.ProcessingStep):\n    \"\"\"\n    Let's combine tables that are next to each other\n    \"\"\"\n\n    def process(self, nodes: List[Node]) -&gt; List[Node]:\n        new_nodes = []\n        print(\"Combining concurrent tables\")\n        for i in range(len(nodes) - 1):\n            if \"table\" in nodes[i].variant and \"table\" in nodes[i + 1].variant:\n                new_node = nodes[i] + nodes[i + 1]\n                new_nodes.append(new_node)\n            else:\n                new_nodes.append(nodes[i])\n\n        return new_nodes\n\n\n# add a custom processing step to the pipeline\ncustom_pipeline = processing.BasicIngestionPipeline()\ncustom_pipeline.append_transform(CustomCombineTables())\n\nparser = openparse.DocumentParser(\n    table_args={\"parsing_algorithm\": \"pymupdf\"}, processing_pipeline=custom_pipeline\n)\ncustom_10k = parser.parse(meta10k_path)\n</code></pre> <p>Or you can create your own custom processing pipeline from scratch by extending the <code>IngestionPipeline</code> class.</p> <pre><code>from openparse import processing, Node\nfrom typing import List\n\n\nclass BasicIngestionPipeline(processing.IngestionPipeline):\n    \"\"\"\n    A basic pipeline for ingesting and processing Nodes.\n    \"\"\"\n\n    def __init__(self):\n        self.transformations = [\n            processing.RemoveTextInsideTables(),\n            processing.RemoveFullPageStubs(max_area_pct=0.35),\n        ]\n</code></pre>"},{"location":"processing/ocr/","title":"Enabling OCR","text":""},{"location":"processing/ocr/#1-default-text-processing-with-pdfminer","title":"1. Default Text Processing with PdfMiner","text":"<p>Use PdfMiner if your documents are text-heavy, well-structured, and do not contain non-text elements that require OCR.</p> <pre><code>parser = openparse.DocumentParser()\nparsed_doc = parser.parse(doc_path)\n</code></pre>"},{"location":"processing/ocr/#2-optionally-ocr-with-pymupdf","title":"2. Optionally OCR with PyMuPDF","text":"<p>If your documents are scanned images or contain non-text elements, you may need to use OCR to extract text. PyMuPDF handles this, see their license here.</p> <p>Use with caution</p> <p>This method is not recommended as a default due to the additional computational cost and inherent inaccuracies of OCR.</p> <pre><code>parser = openparse.DocumentParser()\nparsed_doc = parser.parse(doc_path, ocr=True)\n</code></pre>"},{"location":"processing/overview/","title":"Overview","text":"<p>Processing is how we group related elements together to form a coherent structure. The output are Nodes that represent distinct sections of the document.</p> <p></p>"},{"location":"processing/overview/#documentparser-arguments","title":"<code>DocumentParser</code> Arguments","text":"Argument Type Description <code>processing_pipeline</code> <code>Union[IngestionPipeline, NotGiven, None]</code> A subclass of IngestionPipeline to process extracted elements. Defaults to <code>BasicIngestionPipeline</code>. <code>table_args</code> <code>Union[TableTransformersArgsDict, PyMuPDFArgsDict, UnitableArgsDict, NotGiven]</code> Arguments to customize table parsing."},{"location":"processing/overview/#processing-pipeline","title":"Processing Pipeline","text":""},{"location":"processing/overview/#1-default-processing","title":"1. Default Processing","text":"<p>By default, we use a simple heuristic to group elements together. This works well for many documents.</p> <p>These are mostly just commmon sense transforms - a heading should be grouped with the text that follows it, a bullet list should be grouped together, etc. </p> <pre><code>from openparse import DocumentParser\n\nparser = DocumentParser()\n</code></pre>"},{"location":"processing/overview/#2-semantic-processing-recommended","title":"2. Semantic Processing (Recommended)","text":"<p>Chunking documents is fundamentally about grouping similar semantic nodes together. Perhaps the most powerful way to do this is to use embeddings. By embedding the text of each node, we can then cluster them together based on their similarity. </p> <p>We currently only support the OpenAI API to generate embeddings but plan on adding more options soon.</p> <pre><code>from openparse import processing, DocumentParser\n\nsemantic_pipeline = processing.SemanticIngestionPipeline(\n    openai_api_key=OPEN_AI_KEY,\n    model=\"text-embedding-3-large\",\n    min_tokens=64,\n    max_tokens=1024,\n)\nparser = DocumentParser(\n    processing_pipeline=semantic_pipeline,\n)\nparsed_content = parser.parse(basic_doc_path)\n</code></pre> <p>If you're interested in understand how this works, you can see a demo notebook here.</p>"},{"location":"processing/overview/#notes-on-node-size","title":"Notes on Node Size:","text":"<p>We have a bias towards chunking that results in larger nodes - models have increasingly large context windows and we find large nodes perform better.</p> <p>A more thorough discussion can be found here.</p>"},{"location":"processing/overview/#tables","title":"Tables","text":"<p>See the Table Parsing section for more details on how to customize table parsing.</p>"},{"location":"processing/parsing-tables/overview/","title":"Overview","text":"<p>Automatically identifying and extracting tables from PDF documents is a highly desirable feature that many people are looking for. It's an exciting and active area of research, and our goal is to provide the community with access to the most effective tools available. </p> <p>By default this is turned off. Parsing tables adds significant computational overhead, so we've made it optional.</p> <p>We're expose both cutting-edge deep learning techniques with traditional bounding box-based methods. Our approach is designed to be flexible, allowing users to select the parsing algorithm that works best for their specific requirements.</p> <p>At the moment, we offer three options for extracting tables from PDFs: <code>unitable</code>, <code>pymupdf</code>, and <code>table-transformer</code>. Each of these methods has its own unique advantages and limitations, so you can choose the one that aligns with your needs. </p> <pre><code>parser = openparse.DocumentParser(\n    table_args={...}\n)\n\n# ingesting the document\nparsed_10k = parser.parse(meta10k_path)\n</code></pre>"},{"location":"processing/parsing-tables/overview/#become-a-contributor","title":"Become a Contributor?","text":"<p>Become a Contributor</p> <ul> <li>If you have experience with quantizing models or optimizing them for inference, we would love to hear from you! Unitable achieves state-of-the-art performance on table extraction, but it is computationally expensive. We are looking to optimize the model for inference and reduce the size of the model.</li> </ul>"},{"location":"processing/parsing-tables/pymupdf/","title":"Pymupdf","text":"<p>PyMuPDF is a Python binding for the MuPDF library, which is a lightweight PDF, XPS and e-book viewer. </p> <p>With version 1.23.0, PyMuPDF has added table recognition and extraction facilities to its rich set of features.</p> <p>We find it tends to work well on dense tables, with a relatively simple structure. It's also very fast.</p>"},{"location":"processing/parsing-tables/pymupdf/#parameters","title":"Parameters:","text":"Name Type Description Default parsing_algorithm <code>Literal['pymupdf']</code> The library used for parsing, in this case, <code>pymupdf</code>. None min_table_confidence <code>float</code> The minimum confidence score for a table to be extracted. <code>0.75</code> table_output_format <code>Literal['html\\|markdown']</code> The format of the extracted tables. Currently only <code>html</code> and <code>markdown</code> are supported. <code>'html'</code>"},{"location":"processing/parsing-tables/pymupdf/#example","title":"Example","text":"<p>In the following example, we parse a 10-K document and extract the tables in markdown format.</p> <pre><code># defining the parser (table_args is a dict)\nparser = openparse.DocumentParser(\n    table_args={\n        \"parsing_algorithm\": \"pymupdf\",\n        \"table_output_format\": \"markdown\"\n    }\n)\n\n# ingesting the document\nparsed_10k = parser.parse(meta10k_path)\n</code></pre>"},{"location":"processing/parsing-tables/table-transformers/","title":"Table Transformer","text":"<p>Table Transformers is a deep learning approach to table detection and extraction. It is part of the Hugging Face Transformers library.</p> <p>ML Dependencies Required</p> <p>To use this method, you will need to install the ml dependencies by running <code>pip install \"openparse[ml]\"</code>.</p> <p>We find it works well on tables with more complex structures and significant whitespace.</p>"},{"location":"processing/parsing-tables/table-transformers/#parameters","title":"Parameters","text":"Name Type Description Default <code>parsing_algorithm</code> <code>Literal[\"table-transformers\"]</code> The library used for parsing, in this case, table-transformers. None <code>min_table_confidence</code> <code>float</code> The minimum confidence score for a table to be extracted. None <code>min_cell_confidence</code> <code>float</code> The minimum confidence score for a cell to be extracted. None <code>table_output_format</code> <code>Literal[\"markdown\", \"html\"]</code> The format of the extracted tables. Supports both markdown and html. None"},{"location":"processing/parsing-tables/table-transformers/#example","title":"Example","text":"<pre><code>parser = openparse.DocumentParser(\n    table_args={\n        \"parsing_algorithm\": \"table-transformers\",\n        \"min_table_confidence\": 0.8,\n    }\n)\nparsed_doc2 = parser.parse(doc_with_tables_path)\n</code></pre>"},{"location":"processing/parsing-tables/unitable/","title":"Unitable","text":"<p>Unitable is a deep learning approach to table detection and extraction.  It achieves state-of-the-art (SOTA) performance on four of the largest TR datasets. If table accuracy is your primary concern, this is the method to use.</p> <p>Full credit goes to ShengYun (Anthony) Peng and his team for open sourcing their research in a reproducible manner. You can find the original repository with full training code here. We choose to directly use a small subset of their package along with their pre-trained weights.</p>"},{"location":"processing/parsing-tables/unitable/#installation","title":"Installation","text":"<p>ML Dependencies Required</p> <p>To use this method, you will need to install the ml dependencies by running <code>pip install \"openparse[ml]\"</code>.</p> <p>Once you have pip installed openparse, you will need to download the weights of the model seperately by running the following command.</p> <pre><code>$ openparse-download\n</code></pre> <p>Which will download the weights. They're about 1.5GB in size.</p>"},{"location":"processing/parsing-tables/unitable/#parameters","title":"Parameters","text":"Name Type Description Default <code>parsing_algorithm</code> <code>Literal[\"unitable\"]</code> The library used for parsing, in this case, unitable. None <code>min_table_confidence</code> <code>float</code> The minimum confidence score for a table to be extracted. 0.75 <code>table_output_format</code> <code>Literal[\"html\"]</code> The format of the extracted tables. Currently only support html. None"},{"location":"processing/parsing-tables/unitable/#example","title":"Example","text":"<pre><code>parser = openparse.DocumentParser(\n    table_args={\n        \"parsing_algorithm\": \"unitable\",\n        \"min_table_confidence\": 0.8,\n    }\n)\nparsed_doc = parser.parse(doc_with_tables_path)\n</code></pre>"},{"location":"processing/parsing-tables/unitable/#limitations","title":"Limitations","text":"<ul> <li>This method is very computationally expensive. We recommend using it on a GPU.</li> <li>We currently use the table-transformers model to detect table locations. This model is not perfect and may miss some tables or crop them incorrectly. This negatively impacts the performance of unitable. We're actively looking at more robust models.</li> </ul>"}]}